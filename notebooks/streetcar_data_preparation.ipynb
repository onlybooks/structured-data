{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "streetcar_data_preparation.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deep-diver/deeplearning-with-structured-data/blob/master/notebooks/streetcar_data_preparation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wj7KYAXq4FK6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4373629d-845b-49d5-e44a-996b44f06f97"
      },
      "source": [
        "!git clone https://github.com/deep-diver/deeplearning-with-structured-data.git\n",
        "!mv deeplearning-with-structured-data/* ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deeplearning-with-structured-data'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (277/277), done.\u001b[K\n",
            "remote: Compressing objects: 100% (139/139), done.\u001b[K\n",
            "remote: Total 277 (delta 115), reused 263 (delta 106), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (277/277), 21.36 MiB | 25.03 MiB/s, done.\n",
            "Resolving deltas: 100% (115/115), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YutJ325P2e0c"
      },
      "source": [
        "# 경전철 지연 예측 - 데이터 준비\n",
        "\n",
        "미래의 지연을 예측을 예측하고, 지연 발생에 대한 조언을 구하고자 토론토 교통국(TTC)의 경전철 지연 데이터 중 2014년 - 현재까지를 포함한 데이터셋을 사용합니다.\n",
        "\n",
        "원본 데이터셋의 위치: https://open.toronto.ca/dataset/ttc-streetcar-delay-data/\n",
        "\n",
        "이 노트북은 일반적인 데이터 불러오기, 준비 과정을 다룹니다:\n",
        "- 모든 XLS 파일의 모든 스프레드시트를 단일 데이터프레임으로 만듭니다\n",
        "- 데이터 유형의 문제를 수정\n",
        "- 누락된 값 고치기\n",
        "- 경로(route), 위치(location), 방향(direction), 차량(vehicle) 열의 잘못된 값을 정리합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqyzAPqR2e0f"
      },
      "source": [
        "# 경전철 경로(routes)\n",
        "\n",
        "출처: https://www.ttc.ca/Routes/Streetcars.jsp\n",
        "\n",
        "<table style=\"border: none\" align=\"left\">\n",
        "   </tr>\n",
        "   <tr style=\"border: none\">\n",
        "       <th style=\"border: none\"><img src=\"https://raw.githubusercontent.com/ryanmark1867/streetcarnov3/master/streetcar%20routes.jpg\" width=\"600\" alt=\"Icon\"> </th>\n",
        "   </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvatb5Js2e0g"
      },
      "source": [
        "# 공통 라이브러리 및 변수\n",
        "노트북 전체에서 공통적으로 사용되는 변수를 정의하고 라이브러리를 불러옵니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZQIILWD2e0g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b87cca6-0a98-47c2-da1f-afa7844a559d"
      },
      "source": [
        "!pip install requests\n",
        "!pip install xlrd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.5.30)\n",
            "Requirement already satisfied: xlrd in /usr/local/lib/python3.7/dist-packages (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a-XSru-2e0i"
      },
      "source": [
        "# 선형 대수용 라이브러리\n",
        "import numpy as np \n",
        "\n",
        "# 데이터 처리용 라이브러리로 CSV 파일 입출력을 위해 불러옵니다(예. pd.read_csv)\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "\n",
        "# 공통 라이브러리\n",
        "import zipfile\n",
        "import time\n",
        "# import datetime, timedelta\n",
        "import datetime\n",
        "from datetime import datetime, timedelta\n",
        "from datetime import date\n",
        "from dateutil import relativedelta\n",
        "from io import StringIO\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.base import TransformerMixin\n",
        "from io import StringIO\n",
        "import requests\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "import os\n",
        "import math\n",
        "from subprocess import check_output\n",
        "from IPython.display import display\n",
        "import logging\n",
        "import yaml\n",
        "from collections import Counter\n",
        "import re\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9MvCNmz2e0i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f7ddbb-dd49-4485-d74b-36409ce8ee34"
      },
      "source": [
        "# 설정 파일을 불러옵니다\n",
        "current_path = os.getcwd()\n",
        "# Google Colab 외 환경에서는 아래의 코드를 주석처리 합니다\n",
        "current_path = os.path.join(current_path, \"notebooks\")\n",
        "print(\"현재 디렉터리: \"+current_path)\n",
        "\n",
        "path_to_yaml = os.path.join(current_path, 'streetcar_data_preparation_config.yml')\n",
        "print(\"yaml 파일 경로(path_to_yaml): \"+path_to_yaml)\n",
        "try:\n",
        "    with open (path_to_yaml, 'r') as c_file:\n",
        "        config = yaml.safe_load(c_file)\n",
        "except Exception as e:\n",
        "    print('설정 파일을 읽는 데 오류가 발생했습니다')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "현재 디렉터리: /content/notebooks\n",
            "yaml 파일 경로(path_to_yaml): /content/notebooks/streetcar_data_preparation_config.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ejw3Jy0O2e0j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwdWagAm2e0j"
      },
      "source": [
        "\n",
        "# 공통 변수\n",
        "# 원본 또는 저장된 데이터프레임을 불러올지를 제어합니다\n",
        "load_from_scratch = config['general']['load_from_scratch']\n",
        "\n",
        "# 변형된 데이터로 데이터프레임을 저장할지를 제어합니다\n",
        "save_transformed_dataframe = config['general']['save_transformed_dataframe']\n",
        "\n",
        "# 저장된 데이터셋에서 오류가 있는 값을가진 행을 제거할지를 제어합니다\n",
        "remove_bad_values = config['general']['remove_bad_values']\n",
        "\n",
        "# 피클로 저장된 입력 데이터셋의 파일명 (전처리 전)\n",
        "pickled_input_dataframe = config['file_names']['pickled_input_dataframe']\n",
        "\n",
        "# 피클로 저장된 입력 데이터셋의 파일명 (전처리 후)\n",
        "pickled_output_dataframe = config['file_names']['pickled_output_dataframe']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1a9tc4c2e0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3909fa35-cfef-4dab-e54d-8ce21d6beee6"
      },
      "source": [
        "print(\"load_from_scratch 제어 변수: \"+str(load_from_scratch))\n",
        "print(\"save_transformed_dataframe 제어 변수: \"+str(save_transformed_dataframe))\n",
        "print(\"remove_bad_values 제어 변수: \"+str(remove_bad_values))\n",
        "print(\"pickled_input_dataframe 파일명: \"+str(pickled_input_dataframe))\n",
        "print(\"pickled_output_dataframe 파일명: \"+str(pickled_output_dataframe))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load_from_scratch 제어 변수: False\n",
            "save_transformed_dataframe 제어 변수: True\n",
            "remove_bad_values 제어 변수: True\n",
            "pickled_input_dataframe 파일명: 2014_2019.pkl\n",
            "pickled_output_dataframe 파일명: 2014_2019_df_cleaned_remove_bad_values_may16_2020.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE2tQIS-2e0k"
      },
      "source": [
        "# CLRV/ALRV용 경전철 차량 식별자(IDs)\n",
        "\n",
        "출처: https://en.wikipedia.org/wiki/Toronto_streetcar_system_rolling_stock#CLRVs_and_ALRVs\n",
        "\n",
        "<table style=\"border: none\" align=\"left\">\n",
        "   </tr>\n",
        "   <tr style=\"border: none\">\n",
        "       <th style=\"border: none\"><img src=\"https://raw.githubusercontent.com/ryanmark1867/streetcarnov3/master/streetcarCLRV.jpg\" width=\"600\" alt=\"Icon\"> </th>\n",
        "   </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "QozqRl6q2e0k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6bc811c-c182-4a57-c9d8-7b9358a7babe"
      },
      "source": [
        "# CLRV/ALRV에 맞는 차량 식별자들을 모읍니다\n",
        "streetcar_vehicles = list(range(4000,4006))+ list(range(4010,4200)) +  list(range(4200,4252)) + [4900]\n",
        "streetcar_vehicles = streetcar_vehicles + [4400] + list(range(4402,4508))\n",
        "\n",
        "print(\"CLRV/ALRV용 유효한 경전철 목록\",streetcar_vehicles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLRV/ALRV용 유효한 경전철 목록 [4000, 4001, 4002, 4003, 4004, 4005, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 4079, 4080, 4081, 4082, 4083, 4084, 4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095, 4096, 4097, 4098, 4099, 4100, 4101, 4102, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165, 4166, 4167, 4168, 4169, 4170, 4171, 4172, 4173, 4174, 4175, 4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4216, 4217, 4218, 4219, 4220, 4221, 4222, 4223, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4248, 4249, 4250, 4251, 4900, 4400, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4416, 4417, 4418, 4419, 4420, 4421, 4422, 4423, 4424, 4425, 4426, 4427, 4428, 4429, 4430, 4431, 4432, 4433, 4434, 4435, 4436, 4437, 4438, 4439, 4440, 4441, 4442, 4443, 4444, 4445, 4446, 4447, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4490, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4504, 4505, 4506, 4507]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBSAhLL82e0l"
      },
      "source": [
        "# 경전철 차량 식별자(IDs) 범위의 특이사항\n",
        "\n",
        "출처: https://en.wikipedia.org/wiki/Toronto_streetcar_system_rolling_stock#CLRVs_and_ALRVs\n",
        "\n",
        "<table style=\"border: none\" align=\"left\">\n",
        "   </tr>\n",
        "   <tr style=\"border: none\">\n",
        "       <th style=\"border: none\"><img src=\"https://raw.githubusercontent.com/ryanmark1867/streetcarnov3/master/streetcarflexity.jpg\" width=\"600\" alt=\"Icon\"> </th>\n",
        "   </tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6NUoOfv2e0l"
      },
      "source": [
        "# 버스 식별자\n",
        "\n",
        "아래의 링크는 경전철에 의해 지연될 수 있는, 경전철이 아닌 유효 차량을 정의합니다\n",
        "\n",
        "- 버스 1xxx: https://cptdb.ca/wiki/index.php/Toronto_Transit_Commission_1000-1149\n",
        "- 버스 2xxx: https://cptdb.ca/wiki/index.php/Toronto_Transit_Commission_2000-2110,_2150-2155,_2240-2485,_2600-2619,_2700-2765,_2767-2858\n",
        "- 버스 70xx: https://cptdb.ca/wiki/index.php/Toronto_Transit_Commission_7000-7134\n",
        "- 버스 74xx: https://cptdb.ca/wiki/index.php/Toronto_Transit_Commission_7400-7499,_7500-7619,_7620-7881\n",
        "- 버스 8xxx: https://cptdb.ca/wiki/index.php/Toronto_Transit_Commission_8000-8099\n",
        "- 버스 9xxx: https://cptdb.ca/wiki/index.php/Toronto_Transit_Commission_9000-9026\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4SHt_Zm2e0l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68afd07d-78a9-4e94-b9bc-0136a1140c16"
      },
      "source": [
        "bus_vehicles = list(range(1000,1150))+ list(range(2000,2111)) + list(range(2150,2156)) + list(range(2240,2486))\n",
        "bus_vehicles = bus_vehicles + list(range(2600,2620)) + list(range(2700,2766)) + list(range(2767,2859))\n",
        "bus_vehicles = bus_vehicles + list(range(7000,7135)) + list(range(7400,7450)) + list(range(7500,7620)) + list(range(7620,7882))\n",
        "bus_vehicles = bus_vehicles + list(range(8000,8100)) + list(range(9000,9027))\n",
        "valid_vehicles = streetcar_vehicles + bus_vehicles\n",
        "\n",
        "print(\"유효한 차량 목록\",valid_vehicles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "유효한 차량 목록 [4000, 4001, 4002, 4003, 4004, 4005, 4010, 4011, 4012, 4013, 4014, 4015, 4016, 4017, 4018, 4019, 4020, 4021, 4022, 4023, 4024, 4025, 4026, 4027, 4028, 4029, 4030, 4031, 4032, 4033, 4034, 4035, 4036, 4037, 4038, 4039, 4040, 4041, 4042, 4043, 4044, 4045, 4046, 4047, 4048, 4049, 4050, 4051, 4052, 4053, 4054, 4055, 4056, 4057, 4058, 4059, 4060, 4061, 4062, 4063, 4064, 4065, 4066, 4067, 4068, 4069, 4070, 4071, 4072, 4073, 4074, 4075, 4076, 4077, 4078, 4079, 4080, 4081, 4082, 4083, 4084, 4085, 4086, 4087, 4088, 4089, 4090, 4091, 4092, 4093, 4094, 4095, 4096, 4097, 4098, 4099, 4100, 4101, 4102, 4103, 4104, 4105, 4106, 4107, 4108, 4109, 4110, 4111, 4112, 4113, 4114, 4115, 4116, 4117, 4118, 4119, 4120, 4121, 4122, 4123, 4124, 4125, 4126, 4127, 4128, 4129, 4130, 4131, 4132, 4133, 4134, 4135, 4136, 4137, 4138, 4139, 4140, 4141, 4142, 4143, 4144, 4145, 4146, 4147, 4148, 4149, 4150, 4151, 4152, 4153, 4154, 4155, 4156, 4157, 4158, 4159, 4160, 4161, 4162, 4163, 4164, 4165, 4166, 4167, 4168, 4169, 4170, 4171, 4172, 4173, 4174, 4175, 4176, 4177, 4178, 4179, 4180, 4181, 4182, 4183, 4184, 4185, 4186, 4187, 4188, 4189, 4190, 4191, 4192, 4193, 4194, 4195, 4196, 4197, 4198, 4199, 4200, 4201, 4202, 4203, 4204, 4205, 4206, 4207, 4208, 4209, 4210, 4211, 4212, 4213, 4214, 4215, 4216, 4217, 4218, 4219, 4220, 4221, 4222, 4223, 4224, 4225, 4226, 4227, 4228, 4229, 4230, 4231, 4232, 4233, 4234, 4235, 4236, 4237, 4238, 4239, 4240, 4241, 4242, 4243, 4244, 4245, 4246, 4247, 4248, 4249, 4250, 4251, 4900, 4400, 4402, 4403, 4404, 4405, 4406, 4407, 4408, 4409, 4410, 4411, 4412, 4413, 4414, 4415, 4416, 4417, 4418, 4419, 4420, 4421, 4422, 4423, 4424, 4425, 4426, 4427, 4428, 4429, 4430, 4431, 4432, 4433, 4434, 4435, 4436, 4437, 4438, 4439, 4440, 4441, 4442, 4443, 4444, 4445, 4446, 4447, 4448, 4449, 4450, 4451, 4452, 4453, 4454, 4455, 4456, 4457, 4458, 4459, 4460, 4461, 4462, 4463, 4464, 4465, 4466, 4467, 4468, 4469, 4470, 4471, 4472, 4473, 4474, 4475, 4476, 4477, 4478, 4479, 4480, 4481, 4482, 4483, 4484, 4485, 4486, 4487, 4488, 4489, 4490, 4491, 4492, 4493, 4494, 4495, 4496, 4497, 4498, 4499, 4500, 4501, 4502, 4503, 4504, 4505, 4506, 4507, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2150, 2151, 2152, 2153, 2154, 2155, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 7000, 7001, 7002, 7003, 7004, 7005, 7006, 7007, 7008, 7009, 7010, 7011, 7012, 7013, 7014, 7015, 7016, 7017, 7018, 7019, 7020, 7021, 7022, 7023, 7024, 7025, 7026, 7027, 7028, 7029, 7030, 7031, 7032, 7033, 7034, 7035, 7036, 7037, 7038, 7039, 7040, 7041, 7042, 7043, 7044, 7045, 7046, 7047, 7048, 7049, 7050, 7051, 7052, 7053, 7054, 7055, 7056, 7057, 7058, 7059, 7060, 7061, 7062, 7063, 7064, 7065, 7066, 7067, 7068, 7069, 7070, 7071, 7072, 7073, 7074, 7075, 7076, 7077, 7078, 7079, 7080, 7081, 7082, 7083, 7084, 7085, 7086, 7087, 7088, 7089, 7090, 7091, 7092, 7093, 7094, 7095, 7096, 7097, 7098, 7099, 7100, 7101, 7102, 7103, 7104, 7105, 7106, 7107, 7108, 7109, 7110, 7111, 7112, 7113, 7114, 7115, 7116, 7117, 7118, 7119, 7120, 7121, 7122, 7123, 7124, 7125, 7126, 7127, 7128, 7129, 7130, 7131, 7132, 7133, 7134, 7400, 7401, 7402, 7403, 7404, 7405, 7406, 7407, 7408, 7409, 7410, 7411, 7412, 7413, 7414, 7415, 7416, 7417, 7418, 7419, 7420, 7421, 7422, 7423, 7424, 7425, 7426, 7427, 7428, 7429, 7430, 7431, 7432, 7433, 7434, 7435, 7436, 7437, 7438, 7439, 7440, 7441, 7442, 7443, 7444, 7445, 7446, 7447, 7448, 7449, 7500, 7501, 7502, 7503, 7504, 7505, 7506, 7507, 7508, 7509, 7510, 7511, 7512, 7513, 7514, 7515, 7516, 7517, 7518, 7519, 7520, 7521, 7522, 7523, 7524, 7525, 7526, 7527, 7528, 7529, 7530, 7531, 7532, 7533, 7534, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542, 7543, 7544, 7545, 7546, 7547, 7548, 7549, 7550, 7551, 7552, 7553, 7554, 7555, 7556, 7557, 7558, 7559, 7560, 7561, 7562, 7563, 7564, 7565, 7566, 7567, 7568, 7569, 7570, 7571, 7572, 7573, 7574, 7575, 7576, 7577, 7578, 7579, 7580, 7581, 7582, 7583, 7584, 7585, 7586, 7587, 7588, 7589, 7590, 7591, 7592, 7593, 7594, 7595, 7596, 7597, 7598, 7599, 7600, 7601, 7602, 7603, 7604, 7605, 7606, 7607, 7608, 7609, 7610, 7611, 7612, 7613, 7614, 7615, 7616, 7617, 7618, 7619, 7620, 7621, 7622, 7623, 7624, 7625, 7626, 7627, 7628, 7629, 7630, 7631, 7632, 7633, 7634, 7635, 7636, 7637, 7638, 7639, 7640, 7641, 7642, 7643, 7644, 7645, 7646, 7647, 7648, 7649, 7650, 7651, 7652, 7653, 7654, 7655, 7656, 7657, 7658, 7659, 7660, 7661, 7662, 7663, 7664, 7665, 7666, 7667, 7668, 7669, 7670, 7671, 7672, 7673, 7674, 7675, 7676, 7677, 7678, 7679, 7680, 7681, 7682, 7683, 7684, 7685, 7686, 7687, 7688, 7689, 7690, 7691, 7692, 7693, 7694, 7695, 7696, 7697, 7698, 7699, 7700, 7701, 7702, 7703, 7704, 7705, 7706, 7707, 7708, 7709, 7710, 7711, 7712, 7713, 7714, 7715, 7716, 7717, 7718, 7719, 7720, 7721, 7722, 7723, 7724, 7725, 7726, 7727, 7728, 7729, 7730, 7731, 7732, 7733, 7734, 7735, 7736, 7737, 7738, 7739, 7740, 7741, 7742, 7743, 7744, 7745, 7746, 7747, 7748, 7749, 7750, 7751, 7752, 7753, 7754, 7755, 7756, 7757, 7758, 7759, 7760, 7761, 7762, 7763, 7764, 7765, 7766, 7767, 7768, 7769, 7770, 7771, 7772, 7773, 7774, 7775, 7776, 7777, 7778, 7779, 7780, 7781, 7782, 7783, 7784, 7785, 7786, 7787, 7788, 7789, 7790, 7791, 7792, 7793, 7794, 7795, 7796, 7797, 7798, 7799, 7800, 7801, 7802, 7803, 7804, 7805, 7806, 7807, 7808, 7809, 7810, 7811, 7812, 7813, 7814, 7815, 7816, 7817, 7818, 7819, 7820, 7821, 7822, 7823, 7824, 7825, 7826, 7827, 7828, 7829, 7830, 7831, 7832, 7833, 7834, 7835, 7836, 7837, 7838, 7839, 7840, 7841, 7842, 7843, 7844, 7845, 7846, 7847, 7848, 7849, 7850, 7851, 7852, 7853, 7854, 7855, 7856, 7857, 7858, 7859, 7860, 7861, 7862, 7863, 7864, 7865, 7866, 7867, 7868, 7869, 7870, 7871, 7872, 7873, 7874, 7875, 7876, 7877, 7878, 7879, 7880, 7881, 8000, 8001, 8002, 8003, 8004, 8005, 8006, 8007, 8008, 8009, 8010, 8011, 8012, 8013, 8014, 8015, 8016, 8017, 8018, 8019, 8020, 8021, 8022, 8023, 8024, 8025, 8026, 8027, 8028, 8029, 8030, 8031, 8032, 8033, 8034, 8035, 8036, 8037, 8038, 8039, 8040, 8041, 8042, 8043, 8044, 8045, 8046, 8047, 8048, 8049, 8050, 8051, 8052, 8053, 8054, 8055, 8056, 8057, 8058, 8059, 8060, 8061, 8062, 8063, 8064, 8065, 8066, 8067, 8068, 8069, 8070, 8071, 8072, 8073, 8074, 8075, 8076, 8077, 8078, 8079, 8080, 8081, 8082, 8083, 8084, 8085, 8086, 8087, 8088, 8089, 8090, 8091, 8092, 8093, 8094, 8095, 8096, 8097, 8098, 8099, 9000, 9001, 9002, 9003, 9004, 9005, 9006, 9007, 9008, 9009, 9010, 9011, 9012, 9013, 9014, 9015, 9016, 9017, 9018, 9019, 9020, 9021, 9022, 9023, 9024, 9025, 9026]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxG4VNar2e0m"
      },
      "source": [
        "# 경전철 사건과는 무관한 차량\n",
        "아래의 차량은 완전히 분리된 도로를 사용하거나, 이제는 퇴역(사용되지않는) 버스로 경전철 사건과는 무관합니다.\n",
        "\n",
        "- RT 차량 3xxx: https://cptdb.ca/wiki/index.php/Toronto_Transit_Commission_3000-3027\n",
        "- 지하철 차량 5xxx https://cptdb.ca/wiki/index.php/Toronto_Transit_Commission_5000-5371\n",
        "- 퇴역 차량 6xxx: https://cptdb.ca/wiki/index.php/Toronto_Transit_Commission_6000-6122\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjm6BMeA2e0m"
      },
      "source": [
        "# 유효한 TTC 경전철 경로 목록\n",
        "valid_routes = ['501','502','503','504','505','506','509','510','511','512','301','304','306','310']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjguXiHw2e0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147b504e-5f43-44be-d48a-40efd35f1789"
      },
      "source": [
        "valid_routes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['501',\n",
              " '502',\n",
              " '503',\n",
              " '504',\n",
              " '505',\n",
              " '506',\n",
              " '509',\n",
              " '510',\n",
              " '511',\n",
              " '512',\n",
              " '301',\n",
              " '304',\n",
              " '306',\n",
              " '310']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9HxO8XC2e0m"
      },
      "source": [
        "# 유효한 방향 (원본)\n",
        "# valid_directions = ['E/B','W/B','N/B','S/B','B/W']\n",
        "# 여기서 '/' 문자를 제거한 뒤 소문자 처리를 합니다 (간소화 작업)\n",
        "valid_directions = ['e','w','n','s','b']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kzGbsKp2e0m"
      },
      "source": [
        "valid_days = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beN4_uLe2e0n"
      },
      "source": [
        "# 데이터 불러오기와 저장하기\n",
        "- XLS 파일 목록을 파싱합니다\n",
        "- XLS 파일에 포함된 스프레드를 데이터프레임으로 만듭니다\n",
        "- 이후 작업을 위해 데이터프레임을 피클로 저장합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7o787Rj2e0n"
      },
      "source": [
        "# 현재 노트북이 담긴 디렉터리를 가져온 뒤, 이에 기반하여 데이터가 포함된 디렉터리를 반환합니다\n",
        "\n",
        "def get_path():\n",
        "    rawpath = os.getcwd()\n",
        "    # 데이터는 \"data\" 디렉터리에 들어있으며, \"notebooks\" 디렉터리와 같은 계위에 위치합니다\n",
        "    # 지금부터의 코드는 모든 XLS 파일이 \"data\" 디렉터리에 존재한다고 가정합니다.\n",
        "    # 예제소스가 담긴 저장소를 복제하면 모든 파일이 이미 들어있습니다.\n",
        "    path_to_yaml = os.path.join(current_path, 'notebooks', 'streetcar_data_preparation_config.yml')\n",
        "\n",
        "    # Google Colab을 사용하지 않는 경우, 아래의 코드를 다음과 같이 대체합니다\n",
        "    # path = os.path.abspath(os.path.join(rawpath, '..', 'data'))\n",
        "    path = os.path.abspath(os.path.join(rawpath, 'data'))\n",
        "    return(path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elXTwuSf2e0n"
      },
      "source": [
        "# 주어진 경로에 기반해 모든 xls 파일 목록을 반환합니다\n",
        "def get_xls_list(path):\n",
        "    files = os.listdir(path)\n",
        "    files_xls = [f for f in files if f[-4:] == 'xlsx']\n",
        "    print(files)\n",
        "    print(files_xls)\n",
        "    return(files_xls)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X03l3qIL2e0n"
      },
      "source": [
        "def load_xls(path, files_xls, firstfile, firstsheet, df):\n",
        "    '''\n",
        "    모든 XLS 파일의 모든 탭(스프레드시트)를 불러옵니다.\n",
        "    단 최초 데이터프레임을 생성할 때 사용한 스프레드시트는 이 과정에서 제외합니다\n",
        "    \n",
        "    파라미터:\n",
        "    path: XLS 파일을 담은 경로\n",
        "    files_xls: XLS 파일 목록(리스트)\n",
        "    firstfile: 이 함수가 호출되기 전 이미 불러와진, 첫 번째 탭을 소유한 파일명\n",
        "    firstsheet: 이 함수가 호출되기 전 이미 불러와진 첫 번째 탭의 이름\n",
        "    df: 이 함수가 호출되기 전 이미 불러와진 첫 번째 탭을 포함하고 있다가,\n",
        "        이 함수가 종료될 때는 모든 데이터를 이어붙여 완성된 팬더스 데이터프레임\n",
        "    \n",
        "    반환:\n",
        "    df: 갱신된 데이터프레임\n",
        "    \n",
        "    '''\n",
        "    for f in files_xls:\n",
        "        print(\"file name\",f)\n",
        "        xlsf = pd.ExcelFile(os.path.join(path,f))\n",
        "        # 포함된 모든 스프레드시트를 반복적으로 접근합니다\n",
        "        for sheet_name in xlsf.sheet_names:\n",
        "            print(\"스프레드시트 이름(sheet_name):\",sheet_name)\n",
        "            if (f != firstfile) or (sheet_name != firstsheet):\n",
        "                print(\"대상 스프레드시트 이름:\",sheet_name)\n",
        "                data = pd.read_excel(os.path.join(path,f),sheet_name=sheet_name)    \n",
        "                df = df.append(data)\n",
        "    return (df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4ak13uF2e0n"
      },
      "source": [
        "# 주어진 경로내 모든 XLS 파일을 불러온 후\n",
        "# 주어진 파일명으로 데이터프레임을 저장합니다\n",
        "def reloader(path,picklename):\n",
        "    # 경로내 모든 XLS 파일 목록을 가져옵니다\n",
        "    files_xls = get_xls_list(path)\n",
        "    print(\"xls 파일 목록\",files_xls)\n",
        "\n",
        "    # 첫 번째 XLS 파일내 첫 번째 탭(스프레드시트)로 초기 데이터프레임을 만듭니다\n",
        "    dfnew = pd.read_excel(os.path.join(path,files_xls[0]))\n",
        "\n",
        "    # 첫 번째 파일내 스프레드시트 목록을 가져옵니다\n",
        "    xlsf = pd.ExcelFile(os.path.join(path,files_xls[0]))\n",
        "\n",
        "    # 다른 모든 XLS 파일내 모든 탭을 불러옵니다\n",
        "    # 이 때 앞서 정의한 load_xls 함수에는 첫 번째 XLS 파일과, 초기 데이터프레임 구성에 사용된 탭 이름을 전달합니다\n",
        "    dflatest = load_xls(path,files_xls,files_xls[0],xlsf.sheet_names[0], dfnew)\n",
        "\n",
        "    # 구축된 데이터프레임을 피클로 저장합니다\n",
        "    dflatest.to_pickle(os.path.join(path,picklename))\n",
        "\n",
        "    # 모든 XLS 파일의 모든 탭을 담은 데이터프레임을 반환합니다\n",
        "    return(dflatest)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOgYz9ez2e0o"
      },
      "source": [
        "# 입력 열들을 유형에 맞게 분류합니다\n",
        "def define_feature_categories(df):\n",
        "    allcols = list(df)\n",
        "    print(\"전체 열 목록:\",allcols)\n",
        "    textcols = ['Incident','Location'] \n",
        "    continuouscols = ['Min Delay','Min Gap'] \n",
        "                      # 연속형 값을 다루는 열 - 이후(모델링시) 이 열에는 임베딩을 사용하지 않습니다\n",
        "    timecols = ['Report Date','Time']\n",
        "    collist = ['Day','Vehicle','Route','Direction']\n",
        "    for col in continuouscols:\n",
        "        df[col] = df[col].astype(float)\n",
        "    print('텍스트 열 목록(textcols): ',textcols)\n",
        "    print('연속형 열 목록(continuouscols): ',continuouscols)\n",
        "    print('시간형 열 목록(timecols): ',timecols)\n",
        "    print('범주형 열 목록(collist): ',collist)\n",
        "    return(allcols,textcols,continuouscols,timecols,collist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HfQ1s292e0o"
      },
      "source": [
        "# 열 유형에 맞게 누락된 값을 채워넣습니다\n",
        "def fill_missing(dataset,allcols,textcols,continuouscols,timecols,collist):\n",
        "    logging.debug(\"before mv\")\n",
        "    for col in collist:\n",
        "        dataset[col].fillna(value=\"missing\", inplace=True)\n",
        "    for col in continuouscols:\n",
        "        dataset[col].fillna(value=0.0,inplace=True)\n",
        "    for col in textcols:\n",
        "        dataset[col].fillna(value=\"missing\", inplace=True)\n",
        "    return (dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBGon7eq2e0o"
      },
      "source": [
        "# 데이터프레임 불러오기\n",
        "- 피클로 저장된 데이터프레임을 불러옵니다\n",
        "- 해당 데이터셋의 정보를 출력합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABTBVlpg2e0o"
      },
      "source": [
        "# 원본 XLS 파일 또는 피클로 저장된 데이터프레임의 데이터를 읽습니다\n",
        "def ingest_data(path):\n",
        "    if load_from_scratch:\n",
        "        unpickled_df = reloader(path,pickled_input_dataframe)\n",
        "        logging.debug(\"재읽기 완료\")\n",
        "    else:\n",
        "        unpickled_df = pd.read_pickle(os.path.join(path,pickled_input_dataframe))\n",
        "    return(unpickled_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_pcoSd52e0o"
      },
      "source": [
        "# 일반적인 정리 작업\n",
        "- 경로(Route) 및 차량(Vehicle)의 잘못된 유형 바로잡기\n",
        "- 누락된 값 채워넣기\n",
        "- report-date-time 인덱스 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9lhrKle2e0p"
      },
      "source": [
        "# 2019년도의 데이터에는 일부 이상한 값들이 포함되어 있습니다. 가령,\n",
        "# 2019년도 4월 탭(스프레드시트)에는 무의미한 Incident ID 열이 들어있고,\n",
        "# 2019년도 4, 6월 탭에는 Min Gap, Min Delay로 표시되어야 할 열이 Gap, Delay로 되어있던 문제가 있습니다.\n",
        "# 아래의 함수는 이런 문제를 정리합니다\n",
        "def fix_anomalous_columns(df):\n",
        "    # Min Delay나 Min Gap 열에 NaN 값이 있는 행이 있다면, Delay나 Gap 으로부터 값을 복사해서 채워넣습니다.\n",
        "    # df.Temp_Rating.fillna(df.Farheit, inplace=True)\n",
        "    df['Min Delay'].fillna(df['Delay'], inplace=True)\n",
        "    df['Min Gap'].fillna(df['Gap'], inplace=True)\n",
        "    # now that the useful values have been copied from Delay and Gap, remove them\n",
        "    del df['Delay']\n",
        "    del df['Gap']\n",
        "    # 무의미한 Incident ID 열을 삭제합니다\n",
        "    del df['Incident ID']\n",
        "    return(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0aLAEjf2e0p"
      },
      "source": [
        "def replace_time(date_time_value,time_value):\n",
        "    ''' 주어진 datetime으로 시간 부분을 대체합니다 '''\n",
        "     \n",
        "    date_time_value = date_time_value.replace(hour=time_value.hour,minute=time_value.minute,second=time_value.minute)\n",
        "    return(date_time_value)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QFKIjc52e0p"
      },
      "source": [
        "def general_cleanup(df):\n",
        "    # Route와 Vehicle열 값이 문자열이 되도록 강제합니다\n",
        "    df['Route'] = df['Route'].astype(str)\n",
        "    df['Vehicle'] = df['Vehicle'].astype(str)\n",
        "    # 부동소수를 문자열로 바꾸며 생긴 무의미한 문자(\".0\")를 제거합니다\n",
        "    df['Vehicle'] = df['Vehicle'].str[:-2]\n",
        "    # 열 유형을 분류해 각자의 변수로 저장합니다\n",
        "    allcols,textcols,continuouscols,timecols,collist = define_feature_categories(df)\n",
        "    # 누락된 값을 채워넣습니다\n",
        "    df.isnull().sum(axis = 0)\n",
        "    df = fix_anomalous_columns(df)\n",
        "    df = fill_missing(df,allcols,textcols,continuouscols,timecols,collist)\n",
        "    # 날짜 + 시간을 조함한 새로운 열을 생성한 뒤, 이를 인덱스로 사용합니다\n",
        "    df['Report Date Time'] = df.apply(lambda x: replace_time(x['Report Date'], x['Time']), axis=1)\n",
        "    df.index = df['Report Date Time']\n",
        "    # 갱신된 데이터프레임과 열 유형별 목록을 반환합니다\n",
        "    return(df,allcols,textcols,continuouscols,timecols,collist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Q8vV5It2e0p"
      },
      "source": [
        "# 선택된 열 정리 작업\n",
        "\n",
        "입력 데이터셋의 일부 값은 \"자유 형식\"으로 입력되었습니다. 이런 값을 가진 열에는 다음과 같은것이 있습니다.\n",
        "\n",
        "- Route\n",
        "- Vehicle\n",
        "- Direction\n",
        "- Location\n",
        "\n",
        "각 열은 유한한 고윳값 목록을 가집니다(범주형). 이 열들에 담긴 데이터 중 같은것을 의미하지만 서로다른 토큰이 할당된 문제를 해결해야 합니다(예. \"roncesvalles yard\"와 \"roncesvalles carhouse\"). 또한 잘못된 (유효하지 않은) 값이 입력된 문제도 해결되야 합니다(예. 나침반에 없는 방향 값을 가진 Direction). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMgIPV4l2e0p"
      },
      "source": [
        "# Clean up Route"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuPQZ8Pu2e0p"
      },
      "source": [
        "def check_route (x):\n",
        "    if x in valid_routes:\n",
        "        return(x)\n",
        "    else:\n",
        "        return(\"bad route\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEWDu7J-2e0q"
      },
      "source": [
        "def route_cleanup(df):\n",
        "    print(\"정리 전 Route의 고윳값 개수: \",df['Route'].nunique())\n",
        "    # df['Route'].value_counts()\n",
        "    # 잘못된 경로(route)를 공통 토큰(bad route)으로 대체합니다\n",
        "    df['Route'] = df['Route'].apply(lambda x:check_route(x))\n",
        "    print(\"정리 후 Route의 고윳값 개수: \",df['Route'].nunique())\n",
        "    return(df)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMVQOCLq2e0q"
      },
      "source": [
        "# Vehicle(차량 식별자) 열 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECg-pj5k2e0q"
      },
      "source": [
        "def check_vehicle (x):\n",
        "    if str.isdigit(x):\n",
        "        if int(x) in valid_vehicles:\n",
        "            return x\n",
        "        else:\n",
        "            return(\"bad vehicle\")\n",
        "    else:\n",
        "        return(\"bad vehicle\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsxdFKdA2e0q"
      },
      "source": [
        "def vehicle_cleanup(df):\n",
        "    print(\"정리 전 Vehicle의 고윳값 개수: \",df['Vehicle'].nunique())\n",
        "    df['Vehicle'] = df['Vehicle'].apply(lambda x:check_vehicle(x))\n",
        "    print(\"정리 후 Vehicle의 고윳값 개수\",df['Vehicle'].nunique())\n",
        "    return(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kETN01o2e0q"
      },
      "source": [
        "# Direction(방향) 열 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjyr4LS32e0q"
      },
      "source": [
        "def check_direction (x):\n",
        "    if x in valid_directions:\n",
        "        return(x)\n",
        "    else:\n",
        "        return(\"bad direction\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybkFhPTI2e0q"
      },
      "source": [
        "def direction_cleanup(df):\n",
        "    print(\"정리 전 Direction의 고윳값 개수: \",df['Direction'].nunique())\n",
        "    df['Direction'] = df['Direction'].str.lower()\n",
        "    df['Direction'] = df['Direction'].str.replace('/','')\n",
        "    df['Direction'] = df['Direction'].replace({'eastbound':'e','westbound':'w','southbound':'s','northbound':'n'})\n",
        "    df['Direction'] = df['Direction'].replace('b','',regex=True)\n",
        "    df['Direction'] = df['Direction'].apply(lambda x:check_direction(x))\n",
        "    print(\"정리 후 Direction의 고윳값 개수: \",df['Direction'].nunique())\n",
        "    return(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swr5-qHn2e0r"
      },
      "source": [
        "# Location(위치) 열 정리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUg9g2UH2e0r"
      },
      "source": [
        "def clean_conjunction(intersection):\n",
        "    intersection = re.sub(\" *& *\",\" and \",intersection)\n",
        "    intersection = re.sub(\" */ *\",\" and \",intersection)\n",
        "    return(intersection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5FA6n4T2e0r"
      },
      "source": [
        "def order_location(intersection):\n",
        "    # \" and \"가 중간에 들어있는 모든 문자열에 대해\n",
        "    # 만약 \" and \" 앞에 등장한 문자열 값이 뒤에 등장한 문자열보다 \n",
        "    # 알파벳 순서가 더 높다면, 이 둘의 위치를 뒤바꿉니다\n",
        "    conj = \" and \"\n",
        "    alpha_ordered_intersection = intersection\n",
        "    if conj in intersection:\n",
        "        end_first_street = intersection.find(conj)\n",
        "        if (end_first_street > 0) and (len(intersection) > (end_first_street + len(conj))):\n",
        "            start_second_street = intersection.find(conj) + len(conj)\n",
        "            first_street = intersection[0:end_first_street]\n",
        "            second_street = intersection[start_second_street:]\n",
        "            alpha_ordered_intersection = min(first_street,second_street)+conj+max(first_street,second_street)\n",
        "    return(alpha_ordered_intersection)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VqKqqjg2e0r"
      },
      "source": [
        "def location_cleanup(df):\n",
        "    print(\"정리 전 Location의 고윳값 개수: \",df['Location'].nunique())\n",
        "    # Location 의 모든 값을 소문자로 만듭니다\n",
        "    df['Location'] = df['Location'].str.lower()\n",
        "    # 중복 토큰을 하나의 토큰으로 대체합니다\n",
        "    df['Location'] = df['Location'].replace({'broadviewstation':'broadview station',' at ':' and ',' stn':' station',' ave.':'','/':' and ','roncy':'roncesvalles','carhouse':'yard','yard.':'yard','st. clair':'st clair','ronc. ':'roncesvalles ','long branch':'longbranch','garage':'yard','barns':'yard',' & ':' and '}, regex=True)\n",
        "    # 교차로 문자열 값의 알파벳 순서를 바로잡습니다\n",
        "    df['Location'] = df['Location'].apply(lambda x:order_location(x))\n",
        "    print(\"정리 후 Location의 고윳값 개수: \",df['Location'].nunique())\n",
        "    return(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCsNGOCE2e0r"
      },
      "source": [
        "# 잘못된 값을 가진 행 삭제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTlGy9qB2e0r"
      },
      "source": [
        "# 잘못된 값을 가진 행을 삭제합니다\n",
        "def remove_bad(df):\n",
        "    df = df[df.Vehicle != 'bad vehicle']\n",
        "    df = df[df.Direction != 'bad direction']\n",
        "    df = df[df.Route != 'bad route']\n",
        "    return(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F62T5ALL2e0r",
        "outputId": "1bab0ae8-04d0-490c-c4a0-f19c75bea227"
      },
      "source": [
        "'''\n",
        "# get the path for data files\n",
        "path = get_path()\n",
        "pickled_input_dataframe = '2014_2019_upto_june_from_repo.pkl'\n",
        "print(\"path is \",path)\n",
        "# load route direction and delay data datframes\n",
        "df = ingest_data(path)\n",
        "df.head()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# get the path for data files\\npath = get_path()\\npickled_input_dataframe = \\'2014_2019_upto_june_from_repo.pkl\\'\\nprint(\"path is \",path)\\n# load route direction and delay data datframes\\ndf = ingest_data(path)\\ndf.head()\\n'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2konkUVp2e0r"
      },
      "source": [
        "# Master cell\n",
        "\n",
        "앞서 정의한 모든 정리용 함수를 호출해서, 모든 데이터 정리 작업을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JNsGB7P2e0r",
        "outputId": "eeeb699e-e197-422d-f41d-d342fb1e22cf"
      },
      "source": [
        "# 모든 함수를 호출하는 마스터 셀\n",
        "\n",
        "# 데이터 파일이 들어있는 경로를 가져옵니다\n",
        "path = get_path()\n",
        "print(\"경로는 \",path)\n",
        "\n",
        "# route, direction, delay 데이터를 데이터프레임 형식으로 불러옵니다\n",
        "df = ingest_data(path)\n",
        "print(\"전체 데이터 수: \",len(df.index))\n",
        "print(\"df.info() 출력 내용\",df.info())\n",
        "print(\"df.shape 출력 내용\",df.shape)\n",
        "print(\"df.describe() 출력 내용\",df.describe())\n",
        "print(\"df.types 출력 내용\",df.dtypes)\n",
        "df,allcols,textcols,continuouscols,timecols,collist = general_cleanup(df)\n",
        "df.head()\n",
        "\n",
        "# 연도별 데이터 수를 구합니다\n",
        "from collections import Counter\n",
        "df_year = pd.DatetimeIndex(df['Report Date Time']).year\n",
        "print(\"데이터 전처리 전, 연도별 데이터 개수: \", str(Counter(df_year)))\n",
        "\n",
        "# 2019년도 4월의 값이 올바른지 검사합니다\n",
        "df[df['Report Date Time'].astype(str).str[:7]=='2019-04']\n",
        "\n",
        "# 정리 작업\n",
        "logging.debug(\"정리 전 df.shape 출력 내용\",df.shape)\n",
        "df = route_cleanup(df) \n",
        "df = vehicle_cleanup(df)\n",
        "df = direction_cleanup(df)\n",
        "df = location_cleanup(df)\n",
        "logging.debug(\"정리 후 df.shape 출력 내용\",df.shape)\n",
        "print(\"정리 전 'bad route'의 개수:\",df[df.Route == 'bad route'].shape[0])\n",
        "print(\"정리 전 'bad direction'의 개수:\",df[df.Direction == 'bad direction'].shape[0])\n",
        "print(\"정리 전 'bad vehicle'의 개수:\",df[df.Vehicle == 'bad vehicle'].shape[0])\n",
        "if remove_bad_values:\n",
        "    df = remove_bad(df)\n",
        "print(\"정리 후 'bad route'의 개수:\",df[df.Route == 'bad route'].shape[0])\n",
        "print(\"정리 후 'bad direction'의 개수:\",df[df.Direction == 'bad direction'].shape[0])\n",
        "print(\"정리 후 'bad vehicle'의 개수:\",df[df.Vehicle == 'bad vehicle'].shape[0])\n",
        "\n",
        "# 정리된 데이터프레임을 피클로 저장합니다\n",
        "print(\"잘못된 기록을 삭제한 후 df.shape 출력 내용 \",df.shape)\n",
        "if save_transformed_dataframe:\n",
        "    print(\"경로는 \",path)\n",
        "    file_name = os.path.join(path,pickled_output_dataframe)\n",
        "    print(\"파일명(file_name)은 \",file_name)\n",
        "    df.to_pickle(file_name)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "path is  C:\\personal\\manning\\deep_learning_for_structured_data\\data\n",
            "number of records:  78525\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 78525 entries, 0 to 814\n",
            "Data columns (total 13 columns):\n",
            "Day            78525 non-null object\n",
            "Delay          3444 non-null float64\n",
            "Direction      78217 non-null object\n",
            "Gap            3434 non-null float64\n",
            "Incident       78525 non-null object\n",
            "Incident ID    889 non-null float64\n",
            "Location       78276 non-null object\n",
            "Min Delay      75004 non-null float64\n",
            "Min Gap        74975 non-null float64\n",
            "Report Date    78525 non-null datetime64[ns]\n",
            "Route          78525 non-null int64\n",
            "Time           78525 non-null object\n",
            "Vehicle        73890 non-null float64\n",
            "dtypes: datetime64[ns](1), float64(6), int64(1), object(5)\n",
            "memory usage: 8.4+ MB\n",
            "df.info() output None\n",
            "df.shape output (78525, 13)\n",
            "df.describe() output              Delay          Gap  Incident ID     Min Delay       Min Gap  \\\n",
            "count  3444.000000  3434.000000   889.000000  75004.000000  74975.000000   \n",
            "mean     14.503194    20.133663     3.901012     12.817570     18.304915   \n",
            "std      38.477453    37.362669     2.861142     30.083595     33.678868   \n",
            "min       0.000000     0.000000     1.000000      0.000000      0.000000   \n",
            "25%       5.000000    10.000000     1.000000      5.000000      9.000000   \n",
            "50%       7.000000    14.000000     5.000000      6.000000     12.000000   \n",
            "75%      11.000000    20.000000     7.000000     12.000000     20.000000   \n",
            "max     996.000000   999.000000    10.000000   1400.000000   4216.000000   \n",
            "\n",
            "              Route        Vehicle  \n",
            "count  78525.000000   73890.000000  \n",
            "mean     500.840688    4405.327920  \n",
            "std       45.366162    1570.424282  \n",
            "min        1.000000       0.000000  \n",
            "25%      501.000000    4077.000000  \n",
            "50%      505.000000    4170.000000  \n",
            "75%      509.000000    4412.000000  \n",
            "max      999.000000  163242.000000  \n",
            "df.types output Day                    object\n",
            "Delay                 float64\n",
            "Direction              object\n",
            "Gap                   float64\n",
            "Incident               object\n",
            "Incident ID           float64\n",
            "Location               object\n",
            "Min Delay             float64\n",
            "Min Gap               float64\n",
            "Report Date    datetime64[ns]\n",
            "Route                   int64\n",
            "Time                   object\n",
            "Vehicle               float64\n",
            "dtype: object\n",
            "all cols ['Day', 'Delay', 'Direction', 'Gap', 'Incident', 'Incident ID', 'Location', 'Min Delay', 'Min Gap', 'Report Date', 'Route', 'Time', 'Vehicle']\n",
            "texcols:  ['Incident', 'Location']\n",
            "continuouscols:  ['Min Delay', 'Min Gap']\n",
            "timecols:  ['Report Date', 'Time']\n",
            "collist:  ['Day', 'Vehicle', 'Route', 'Direction']\n",
            "record count by year pre processing:  Counter({2018: 15612, 2016: 14021, 2017: 13762, 2015: 12221, 2019: 11882, 2014: 11027})\n",
            "Route count pre cleanup 117\n",
            "route count post cleanup 15\n",
            "Vehicle count pre cleanup 2663\n",
            "Vehicle count post cleanup 1019\n",
            "Direction count pre cleanup 101\n",
            "Direction count post cleanup 5\n",
            "Location count pre cleanup 17086\n",
            "Location count post cleanup 11000\n",
            "Bad route count pre: 2544\n",
            "Bad direction count pre: 407\n",
            "Bad vehicle count pre: 14656\n",
            "Bad route count: 0\n",
            "Bad direction count: 0\n",
            "Bad vehicle count: 0\n",
            "df.shape output post removal of bad records  (61553, 11)\n",
            "path is  C:\\personal\\manning\\deep_learning_for_structured_data\\data\n",
            "file_name is  C:\\personal\\manning\\deep_learning_for_structured_data\\data\\2014_2019_df_cleaned_remove_bad_values_may16_2020.pkl\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Day</th>\n",
              "      <th>Direction</th>\n",
              "      <th>Incident</th>\n",
              "      <th>Location</th>\n",
              "      <th>Min Delay</th>\n",
              "      <th>Min Gap</th>\n",
              "      <th>Report Date</th>\n",
              "      <th>Route</th>\n",
              "      <th>Time</th>\n",
              "      <th>Vehicle</th>\n",
              "      <th>Report Date Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Report Date Time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>2014-01-02 06:31:31</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>e</td>\n",
              "      <td>Late Leaving Garage</td>\n",
              "      <td>dundas and roncesvalles</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>505</td>\n",
              "      <td>06:31:00</td>\n",
              "      <td>4018</td>\n",
              "      <td>2014-01-02 06:31:31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2014-01-02 12:43:43</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>e</td>\n",
              "      <td>Utilized Off Route</td>\n",
              "      <td>king and shaw</td>\n",
              "      <td>20.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>504</td>\n",
              "      <td>12:43:00</td>\n",
              "      <td>4128</td>\n",
              "      <td>2014-01-02 12:43:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2014-01-02 14:01:01</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>w</td>\n",
              "      <td>Held By</td>\n",
              "      <td>bingham and kingston road</td>\n",
              "      <td>13.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>501</td>\n",
              "      <td>14:01:00</td>\n",
              "      <td>4016</td>\n",
              "      <td>2014-01-02 14:01:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2014-01-02 14:22:22</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>w</td>\n",
              "      <td>Investigation</td>\n",
              "      <td>king st. and roncesvalles</td>\n",
              "      <td>7.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>504</td>\n",
              "      <td>14:22:00</td>\n",
              "      <td>4175</td>\n",
              "      <td>2014-01-02 14:22:22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2014-01-02 16:42:42</td>\n",
              "      <td>Thursday</td>\n",
              "      <td>e</td>\n",
              "      <td>Utilized Off Route</td>\n",
              "      <td>bathurst and king</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>504</td>\n",
              "      <td>16:42:00</td>\n",
              "      <td>4080</td>\n",
              "      <td>2014-01-02 16:42:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Day Direction             Incident  \\\n",
              "Report Date Time                                               \n",
              "2014-01-02 06:31:31  Thursday         e  Late Leaving Garage   \n",
              "2014-01-02 12:43:43  Thursday         e   Utilized Off Route   \n",
              "2014-01-02 14:01:01  Thursday         w              Held By   \n",
              "2014-01-02 14:22:22  Thursday         w        Investigation   \n",
              "2014-01-02 16:42:42  Thursday         e   Utilized Off Route   \n",
              "\n",
              "                                      Location  Min Delay  Min Gap  \\\n",
              "Report Date Time                                                     \n",
              "2014-01-02 06:31:31    dundas and roncesvalles        4.0      8.0   \n",
              "2014-01-02 12:43:43              king and shaw       20.0     22.0   \n",
              "2014-01-02 14:01:01  bingham and kingston road       13.0     19.0   \n",
              "2014-01-02 14:22:22  king st. and roncesvalles        7.0     11.0   \n",
              "2014-01-02 16:42:42          bathurst and king        3.0      6.0   \n",
              "\n",
              "                    Report Date Route      Time Vehicle    Report Date Time  \n",
              "Report Date Time                                                             \n",
              "2014-01-02 06:31:31  2014-01-02   505  06:31:00    4018 2014-01-02 06:31:31  \n",
              "2014-01-02 12:43:43  2014-01-02   504  12:43:00    4128 2014-01-02 12:43:43  \n",
              "2014-01-02 14:01:01  2014-01-02   501  14:01:00    4016 2014-01-02 14:01:01  \n",
              "2014-01-02 14:22:22  2014-01-02   504  14:22:00    4175 2014-01-02 14:22:22  \n",
              "2014-01-02 16:42:42  2014-01-02   504  16:42:00    4080 2014-01-02 16:42:42  "
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-Q9dPDa2e0s",
        "outputId": "9eb7f9e4-47a2-47f7-84be-b713f593e5c1"
      },
      "source": [
        "# get record count by year\n",
        "from collections import Counter\n",
        "df_year = pd.DatetimeIndex(df['Report Date Time']).year\n",
        "Counter(df_year)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Counter({2014: 9371,\n",
              "         2015: 10898,\n",
              "         2016: 11908,\n",
              "         2017: 9891,\n",
              "         2018: 12011,\n",
              "         2019: 7474})"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    }
  ]
}